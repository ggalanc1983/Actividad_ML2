{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Cargar librerías y dataset"
      ],
      "metadata": {
        "id": "d7hSFH7TtqsX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================\n",
        "# LIMPIEZA Y FUSIÓN FINAL DE EVENTOS DE INCENDIO\n",
        "# ==========================================\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.metrics.pairwise import haversine_distances\n",
        "from collections import defaultdict\n",
        "\n",
        "# ------------------------------------------\n",
        "# 1. Cargar dataset\n",
        "# ------------------------------------------\n",
        "df = pd.read_csv(\"/content/sample_data/Dataset_Incendios_y_clima_Final.csv\")\n",
        "\n",
        "# Parseo de fechas\n",
        "df[\"fecha_inicio\"] = pd.to_datetime(df[\"fecha_inicio\"])\n",
        "df[\"time_start\"] = pd.to_datetime(df[\"time_start\"])\n",
        "df[\"time_end\"] = pd.to_datetime(df[\"time_end\"])\n",
        "\n",
        "# ------------------------------------------\n",
        "# 2. Función distancia Haversine (km)\n",
        "# ------------------------------------------\n",
        "def haversine_km(lat1, lon1, lat2, lon2):\n",
        "    coords = np.radians([[lat1, lon1], [lat2, lon2]])\n",
        "    return haversine_distances(coords)[0, 1] * 6371\n",
        "\n",
        "# ------------------------------------------\n",
        "# 3. Detectar eventos fragmentados\n",
        "#    Criterios:\n",
        "#    - misma comuna\n",
        "#    - diferencia inicio <= 24 h\n",
        "#    - distancia <= 1.5 km\n",
        "# ------------------------------------------\n",
        "pairs_to_merge = []\n",
        "\n",
        "for comuna, g in df.groupby(\"comuna\"):\n",
        "    g = g.sort_values(\"fecha_inicio\").reset_index(drop=True)\n",
        "\n",
        "    for i in range(len(g)):\n",
        "        for j in range(i + 1, len(g)):\n",
        "            dt_hours = abs(\n",
        "                (g.loc[j, \"fecha_inicio\"] - g.loc[i, \"fecha_inicio\"])\n",
        "                .total_seconds()\n",
        "            ) / 3600\n",
        "\n",
        "            if dt_hours > 24:\n",
        "                break\n",
        "\n",
        "            dist_km = haversine_km(\n",
        "                g.loc[i, \"latitud\"], g.loc[i, \"longitud\"],\n",
        "                g.loc[j, \"latitud\"], g.loc[j, \"longitud\"]\n",
        "            )\n",
        "\n",
        "            if dist_km <= 1.5:\n",
        "                pairs_to_merge.append(\n",
        "                    (g.loc[i, \"event_id\"], g.loc[j, \"event_id\"])\n",
        "                )\n",
        "\n",
        "# ------------------------------------------\n",
        "# 4. Resolver fusiones (componentes conexas)\n",
        "# ------------------------------------------\n",
        "graph = defaultdict(set)\n",
        "\n",
        "for a, b in pairs_to_merge:\n",
        "    graph[a].add(b)\n",
        "    graph[b].add(a)\n",
        "\n",
        "visited = set()\n",
        "components = []\n",
        "\n",
        "def dfs(node, comp):\n",
        "    for neigh in graph[node]:\n",
        "        if neigh not in visited:\n",
        "            visited.add(neigh)\n",
        "            comp.add(neigh)\n",
        "            dfs(neigh, comp)\n",
        "\n",
        "for node in graph:\n",
        "    if node not in visited:\n",
        "        visited.add(node)\n",
        "        comp = {node}\n",
        "        dfs(node, comp)\n",
        "        components.append(comp)\n",
        "\n",
        "# ------------------------------------------\n",
        "# 5. Crear event_id_final\n",
        "# ------------------------------------------\n",
        "event_map = {}\n",
        "\n",
        "for i, comp in enumerate(components):\n",
        "    new_id = f\"FIRE_{i+1}\"\n",
        "    for old_id in comp:\n",
        "        event_map[old_id] = new_id\n",
        "\n",
        "df[\"event_id_final\"] = df[\"event_id\"].map(event_map)\n",
        "df[\"event_id_final\"] = df[\"event_id_final\"].fillna(df[\"event_id\"])\n",
        "\n",
        "# ------------------------------------------\n",
        "# 6. Reagregar a nivel incendio físico\n",
        "# ------------------------------------------\n",
        "final_df = df.groupby(\"event_id_final\").agg(\n",
        "    comuna=(\"comuna\", \"first\"),\n",
        "    latitud=(\"latitud\", \"mean\"),\n",
        "    longitud=(\"longitud\", \"mean\"),\n",
        "    time_start=(\"time_start\", \"min\"),\n",
        "    time_end=(\"time_end\", \"max\"),\n",
        "    frp_inicial=(\"frp_inicial\", \"min\"),\n",
        "    frp_max=(\"frp_max\", \"max\")\n",
        ").reset_index()\n",
        "\n",
        "final_df[\"duracion_horas\"] = (\n",
        "    (final_df[\"time_end\"] - final_df[\"time_start\"])\n",
        "    .dt.total_seconds() / 3600\n",
        ")\n",
        "\n",
        "final_df[\"delta_frp\"] = final_df[\"frp_max\"] - final_df[\"frp_inicial\"]\n",
        "final_df[\"target_transicion\"] = (final_df[\"delta_frp\"] > 3).astype(int)\n",
        "\n",
        "# ------------------------------------------\n",
        "# 7. Eliminar eventos sin duración (clave)\n",
        "# ------------------------------------------\n",
        "print(\"Eventos antes de filtrar duración 0:\", len(final_df))\n",
        "\n",
        "final_df = final_df[final_df[\"duracion_horas\"] > 0].reset_index(drop=True)\n",
        "\n",
        "print(\"Eventos después de filtrar duración 0:\", len(final_df))\n",
        "\n",
        "# ------------------------------------------\n",
        "# 8. Recuperar variables climáticas\n",
        "#    (evento más temprano)\n",
        "# ------------------------------------------\n",
        "climate_cols = [\n",
        "    c for c in df.columns\n",
        "    if \"lag\" in c or \"_mean\" in c or \"precipitation\" in c\n",
        "]\n",
        "\n",
        "climate_df = (\n",
        "    df.sort_values(\"fecha_inicio\")\n",
        "      .groupby(\"event_id_final\")\n",
        "      .first()[climate_cols]\n",
        "      .reset_index()\n",
        ")\n",
        "\n",
        "final_df = final_df.merge(climate_df, on=\"event_id_final\", how=\"left\")\n",
        "\n",
        "# ------------------------------------------\n",
        "# 9. Auditoría final\n",
        "# ------------------------------------------\n",
        "print(\"\\nEventos antes de fusionar:\", df[\"event_id\"].nunique())\n",
        "print(\"Eventos finales:\", final_df[\"event_id_final\"].nunique())\n",
        "print(\"\\nDistribución del target:\")\n",
        "print(final_df[\"target_transicion\"].value_counts(normalize=True))\n",
        "\n",
        "# ------------------------------------------\n",
        "# 10. Guardar dataset final\n",
        "# ------------------------------------------\n",
        "final_df.to_csv(\n",
        "    \"/content/Dataset_Incendios_Eventos_Fusionados_SinDuracionCero.csv\",\n",
        "    index=False\n",
        ")\n",
        "\n",
        "print(\"\\nDataset final guardado como:\")\n",
        "print(\"Dataset_Incendios_Eventos_Fusionados_SinDuracionCero.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vtMDDVuvlGJq",
        "outputId": "e54f773f-0177-45e7-eca9-f293180f757e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Eventos antes de filtrar duración 0: 34908\n",
            "Eventos después de filtrar duración 0: 7778\n",
            "\n",
            "Eventos antes de fusionar: 67168\n",
            "Eventos finales: 7778\n",
            "\n",
            "Distribución del target:\n",
            "target_transicion\n",
            "1    0.60774\n",
            "0    0.39226\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Dataset final guardado como:\n",
            "Dataset_Incendios_Eventos_Fusionados_SinDuracionCero.csv\n"
          ]
        }
      ]
    }
  ]
}