{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z4kf7GZcp-_"
      },
      "source": [
        "Este script implementa un modelo de Ridge Regression con transformación polinomial de segundo grado aplicado a la predicción del valor máximo de Fire Radiative Power (FRP_max) en eventos de incendios forestales. A partir de esta predicción continua, se construye una clasificación operativa derivada que identifica eventos intensos mediante un umbral fijo de FRP ≥ 100 MW.\n",
        "\n",
        "La incorporación de características polinomiales permite al modelo capturar relaciones no lineales suaves e interacciones simples entre variables climáticas, manteniendo al mismo tiempo la regularización propia de Ridge, lo que controla la complejidad y reduce el riesgo de sobreajuste. De esta forma, el modelo actúa como un baseline no lineal, situado entre la regresión lineal clásica y modelos no paramétricos más complejos.\n",
        "\n",
        "Este enfoque permite evaluar de manera progresiva el impacto de la no linealidad en el desempeño predictivo y operativo del sistema, manteniendo una estructura metodológica clara y comparable con los modelos previamente analizados."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX20aCZFhxZm"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# MODELO 1B — RIDGE REGRESSION CON TRANSFORMACIÓN POLINOMIAL\n",
        "# Clasificación derivada:\n",
        "#   Evento intenso = 1 si FRP_max_predicho ≥ 100\n",
        "# Dataset: Dataset_Incendios_Eventos_TARGET_RIESGO_FRP.csv\n",
        "# ============================================================\n",
        "# Descripción general:\n",
        "# Este modelo extiende Ridge Regression incorporando una transformación\n",
        "# polinomial de grado 2 sobre las variables predictoras. El objetivo es\n",
        "# capturar relaciones no lineales suaves e interacciones simples entre\n",
        "# variables climáticas, manteniendo regularización explícita.\n",
        "#\n",
        "# El modelo sigue siendo una regresión + clasificación derivada y actúa\n",
        "# como un baseline no lineal, intermedio entre Ridge lineal y Random Forest.\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "# -----------------------------\n",
        "# 0) FUNCIÓN MATRIZ DE CONFUSIÓN (PALETA BLUES)\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Función auxiliar para visualizar la matriz de confusión de la clasificación\n",
        "# derivada. Se muestran explícitamente TN, FP, FN y TP, facilitando la lectura\n",
        "# operativa del desempeño del modelo.\n",
        "\n",
        "def plot_confusion_with_labels_blues(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    labels = np.array([\n",
        "        [f\"TN\\n{tn}\", f\"FP\\n{fp}\"],\n",
        "        [f\"FN\\n{fn}\", f\"TP\\n{tp}\"]\n",
        "    ])\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    im = ax.imshow(cm, cmap=\"Blues\")\n",
        "\n",
        "    ax.set_xticks([0, 1])\n",
        "    ax.set_yticks([0, 1])\n",
        "    ax.set_xticklabels([\"Pred 0\", \"Pred 1\"])\n",
        "    ax.set_yticklabels([\"Real 0\", \"Real 1\"])\n",
        "    ax.set_xlabel(\"Predicción\")\n",
        "    ax.set_ylabel(\"Real\")\n",
        "    ax.set_title(title)\n",
        "\n",
        "    thr = cm.max() / 2 if cm.max() > 0 else 0\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            color = \"white\" if cm[i, j] > thr else \"black\"\n",
        "            ax.text(j, i, labels[i, j], ha=\"center\", va=\"center\", color=color)\n",
        "\n",
        "    plt.colorbar(im, ax=ax)\n",
        "    plt.grid(False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 1) CARGA DEL DATASET\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se carga el dataset consolidado de eventos de incendio, que contiene\n",
        "# información climática, FRP inicial, FRP máximo y la etiqueta real de riesgo.\n",
        "\n",
        "DATA_PATH = \"/content/sample_data/Dataset_Incendios_Eventos_TARGET_RIESGO_FRP.csv\"\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "print(\"✅ Dataset cargado\")\n",
        "print(\"Shape:\", df.shape)\n",
        "display(df.head())\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2) CONFIGURACIÓN DE VARIABLES\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se definen explícitamente la variable objetivo de regresión, la etiqueta\n",
        "# real de clasificación y el conjunto de variables predictoras utilizadas.\n",
        "\n",
        "TARGET_REG = \"frp_max\"\n",
        "TARGET_CLASS_REAL = \"target_riesgo\"\n",
        "FRP_INICIAL_COL = \"frp_inicial\"\n",
        "\n",
        "features = [\n",
        "    \"frp_inicial\",\n",
        "    \"temperature_2m_mean\", \"relativehumidity_2m_mean\",\n",
        "    \"windspeed_10m_mean\", \"precipitation_sum\",\n",
        "    \"temperature_2m_mean_lag1\", \"temperature_2m_mean_lag2\", \"temperature_2m_mean_lag3\",\n",
        "    \"relativehumidity_2m_mean_lag1\", \"relativehumidity_2m_mean_lag2\", \"relativehumidity_2m_mean_lag3\",\n",
        "    \"windspeed_10m_mean_lag1\", \"windspeed_10m_mean_lag2\", \"windspeed_10m_mean_lag3\",\n",
        "    \"precipitation_sum_lag1\", \"precipitation_sum_lag2\", \"precipitation_sum_lag3\"\n",
        "]\n",
        "\n",
        "# Validaciones mínimas\n",
        "for col in [TARGET_REG, TARGET_CLASS_REAL, FRP_INICIAL_COL]:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"❌ Falta columna requerida: {col}\")\n",
        "\n",
        "missing = [c for c in features if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"❌ Faltan columnas en features: {missing}\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3) ARMAR X e y (REGRESIÓN)\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se construyen las matrices de entrada (X) y salida (y) para el problema\n",
        "# de regresión. Se eliminan filas inválidas para asegurar consistencia.\n",
        "\n",
        "X = df[features].apply(pd.to_numeric, errors=\"coerce\")\n",
        "y_reg = pd.to_numeric(df[TARGET_REG], errors=\"coerce\")\n",
        "\n",
        "mask = y_reg.notna() & df[FRP_INICIAL_COL].notna()\n",
        "X = X.loc[mask].reset_index(drop=True)\n",
        "y_reg = y_reg.loc[mask].reset_index(drop=True)\n",
        "y_class_real = df.loc[mask, TARGET_CLASS_REAL].astype(int).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nDatos para modelar:\")\n",
        "print(\"X:\", X.shape, \"| y_reg:\", y_reg.shape)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4) TRAIN / TEST SPLIT\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se divide el dataset en entrenamiento y prueba para evaluar el desempeño\n",
        "# del modelo en datos no vistos.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_reg,\n",
        "    test_size=0.30,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 5) PIPELINE: RIDGE + POLINOMIAL + GRIDSEARCH\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se construye un pipeline que incluye:\n",
        "# - Imputación de valores faltantes\n",
        "# - Escalado de variables\n",
        "# - Transformación polinomial de grado 2\n",
        "# - Regresión Ridge\n",
        "#\n",
        "# Se utiliza GridSearchCV para seleccionar el nivel óptimo de regularización.\n",
        "\n",
        "pipe_ridge_poly = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
        "    (\"ridge\", Ridge(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    \"ridge__alpha\": [1, 10, 100, 300, 1000]\n",
        "}\n",
        "\n",
        "gs = GridSearchCV(\n",
        "    pipe_ridge_poly,\n",
        "    param_grid,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "gs.fit(X_train, y_train)\n",
        "model = gs.best_estimator_\n",
        "\n",
        "print(\"\\n✅ Ridge polinomial entrenado\")\n",
        "print(\"Mejor alpha:\", gs.best_params_[\"ridge__alpha\"])\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 6) MÉTRICAS DE REGRESIÓN\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se evalúa el desempeño del modelo en términos de regresión continua\n",
        "# utilizando métricas estándar.\n",
        "\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "print(\"\\nMétricas regresión (test):\")\n",
        "print(\"MAE :\", mean_absolute_error(y_test, y_pred_test))\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
        "print(\"R²  :\", r2_score(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 7) PREDICCIÓN FRP MAX PARA TODO EL DATASET\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se generan predicciones continuas para todos los eventos disponibles.\n",
        "# Se aplica una restricción física para evitar valores negativos.\n",
        "\n",
        "frp_max_pred = model.predict(X)\n",
        "frp_max_pred = np.maximum(frp_max_pred, 0)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 8) CLASIFICACIÓN DERIVADA POR FRP ≥ 100\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se transforma la predicción continua en una clasificación binaria\n",
        "# basada en un umbral operativo fijo.\n",
        "THR_FRP = 100.0\n",
        "pred_intenso = (frp_max_pred >= THR_FRP).astype(int)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 9) DATASET DE SALIDA\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se construye un dataset final que incorpora las predicciones del modelo\n",
        "# y la clasificación derivada, manteniendo trazabilidad con los eventos.\n",
        "df_out = df.loc[mask].copy().reset_index(drop=True)\n",
        "\n",
        "df_out[\"frp_max_pred_ridge_poly\"] = frp_max_pred\n",
        "df_out[\"pred_intenso_frp100\"] = pred_intenso\n",
        "df_out[\"umbral_frp\"] = THR_FRP\n",
        "\n",
        "display(df_out[[\n",
        "    \"event_id_final\",\n",
        "    \"frp_inicial\",\n",
        "    \"frp_max\",\n",
        "    \"frp_max_pred_ridge_poly\",\n",
        "    \"pred_intenso_frp100\",\n",
        "    TARGET_CLASS_REAL\n",
        "]].head())\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 10) MÉTRICAS DE CLASIFICACIÓN\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se evalúa el desempeño del modelo desde una perspectiva operativa,\n",
        "# comparando las predicciones binarias con la etiqueta real de riesgo.\n",
        "\n",
        "prec = precision_score(y_class_real, pred_intenso, zero_division=0)\n",
        "rec  = recall_score(y_class_real, pred_intenso, zero_division=0)\n",
        "f1   = f1_score(y_class_real, pred_intenso, zero_division=0)\n",
        "\n",
        "print(\"\\n================= MÉTRICAS CLASIFICACIÓN ================\")\n",
        "print(f\"Umbral FRP_max_pred ≥ {THR_FRP}\")\n",
        "print(f\"Precision: {prec:.3f}\")\n",
        "print(f\"Recall   : {rec:.3f}\")\n",
        "print(f\"F1       : {f1:.3f}\")\n",
        "\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_class_real, pred_intenso, digits=3, zero_division=0))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 11) MATRIZ DE CONFUSIÓN\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Visualización final de la matriz de confusión para analizar aciertos\n",
        "# y errores del modelo Ridge polinomial.\n",
        "\n",
        "plot_confusion_with_labels_blues(\n",
        "    y_class_real,\n",
        "    pred_intenso,\n",
        "    title=\"Matriz de confusión — Ridge Polinomial (FRP_max_pred ≥ 100)\"\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 12) GUARDAR DATASET (OPCIONAL)\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se exporta el dataset final con las predicciones del modelo para\n",
        "# su uso posterior o comparación con otros enfoques.\n",
        "\n",
        "df_out.to_csv(\n",
        "    \"Dataset_Ridge_Polinomial_FRP100.csv\",\n",
        "    index=False,\n",
        "    sep=\";\",\n",
        "    decimal=\".\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "El modelo Ridge con transformación polinomial muestra una mejora respecto a la versión lineal, evidenciando que la incorporación de no linealidades suaves permite capturar parcialmente patrones adicionales presentes en los datos. Sin embargo, su desempeño sigue siendo limitado frente a enfoques no paramétricos como Random Forest, especialmente en la detección de eventos de incendio intensos (FRP ≥ 100).\n",
        "\n",
        "Desde una perspectiva operativa, el modelo continúa presentando una baja sensibilidad (recall) para la clase de interés, lo que restringe su utilidad en escenarios de alerta temprana. Esto confirma que, aun con características polinomiales, las limitaciones estructurales de los modelos lineales regularizados persisten cuando se enfrentan fenómenos altamente no lineales, con colas pesadas y umbrales abruptos.\n",
        "\n",
        "En consecuencia, el Ridge polinomial cumple adecuadamente su rol como modelo de referencia intermedio, validando que la simple incorporación de no linealidad no es suficiente para abordar plenamente la complejidad del problema. Este resultado refuerza la necesidad de utilizar modelos no lineales más flexibles, como Random Forest o redes neuronales, para aplicaciones orientadas a la detección de incendios severos."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
