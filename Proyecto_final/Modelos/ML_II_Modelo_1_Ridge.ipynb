{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Z4kf7GZcp-_"
      },
      "source": [
        "En esta versión, el modelo Ridge Regression se utiliza como modelo base (baseline) para predecir el valor máximo de FRP (frp_max) y, a partir de dicha predicción continua, construir una clasificación operativa de incendios intensos.\n",
        "\n",
        "**Criterio operativo**\n",
        "\n",
        "Se define un evento intenso de la siguiente manera:\n",
        "\n",
        "Evento intenso = 1 ⇔ FRP máximo predicho ≥ 100\n",
        "\n",
        "Este criterio transforma el problema original de regresión en una clasificación derivada, orientada a la toma de decisiones operativas.\n",
        "\n",
        "**Pipeline del modelo**\n",
        "\n",
        "El flujo de trabajo del modelo se estructura en las siguientes etapas:\n",
        "\n",
        "Carga del dataset consolidado, que contiene variables climáticas, métricas de FRP y la etiqueta real de riesgo.\n",
        "\n",
        "Entrenamiento del modelo Ridge Regression, cuyo objetivo es predecir el valor máximo de FRP (frp_max) a partir de las variables predictoras.\n",
        "\n",
        "Generación de predicciones continuas, obteniendo la variable\n",
        "frp_max_pred_ridge.\n",
        "\n",
        "Clasificación operativa derivada, donde se asigna:\n",
        "\n",
        "evento_intenso_pred = 1 si frp_max_pred_ridge ≥ 100,\n",
        "\n",
        "evento_intenso_pred = 0 en caso contrario.\n",
        "\n",
        "Construcción de un dataset de salida, incorporando las nuevas columnas de predicción y clasificación, manteniendo la trazabilidad con los eventos originales.\n",
        "\n",
        "Evaluación del desempeño en clasificación, utilizando:\n",
        "\n",
        "métricas estándar (precision, recall y F1-score),\n",
        "\n",
        "matriz de confusión visualizada con paleta Blues, con los valores de TN, FP, FN y TP explícitamente rotulados."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sel1kDMZhiJH"
      },
      "source": [
        "*Al evaluar la clasificación derivada para un umbral de FRP ≥ 100 MW, se observa que el modelo Ridge presenta una sensibilidad extremadamente baja (recall ≈ 0.04), a pesar de una precisión moderada. Este comportamiento se explica por la alta regularización del modelo y por el hecho de que el error medio de predicción es del mismo orden de magnitud que el umbral considerado. En consecuencia, el modelo tiende a subestimar eventos intensos, confirmando que enfoques lineales no son adecuados para la detección de incendios de intensidad moderada.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EX20aCZFhxZm"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# MODELO 1 — RIDGE REGRESSION\n",
        "# ============================================================\n",
        "# Descripción general:\n",
        "# Este script implementa un modelo de regresión lineal regularizada (Ridge)\n",
        "# para predecir el valor máximo de FRP (frp_max) de eventos de incendio.\n",
        "# A partir de esta predicción continua, se construye una clasificación\n",
        "# operativa de incendios intensos utilizando un umbral fijo (FRP ≥ 100).\n",
        "#\n",
        "# El modelo Ridge se utiliza como baseline lineal para comparar su desempeño\n",
        "# con modelos no lineales más complejos (Random Forest y MLP).\n",
        "# ============================================================\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import Ridge\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    mean_absolute_error,\n",
        "    mean_squared_error,\n",
        "    r2_score,\n",
        "    confusion_matrix,\n",
        "    classification_report,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 0) FUNCIÓN MATRIZ DE CONFUSIÓN (PALETA BLUES)\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se define una función auxiliar para visualizar la matriz de confusión\n",
        "# correspondiente a la clasificación derivada. La visualización muestra\n",
        "# explícitamente los verdaderos y falsos positivos y negativos, facilitando\n",
        "# la interpretación del desempeño del modelo en términos operativos.\n",
        "\n",
        "def plot_confusion_with_labels_blues(y_true, y_pred, title):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "\n",
        "    labels = np.array(\n",
        "        [\n",
        "            [f\"TN\\n{tn}\", f\"FP\\n{fp}\"],\n",
        "            [f\"FN\\n{fn}\", f\"TP\\n{tp}\"]\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(6, 5))\n",
        "    im = ax.imshow(cm, cmap=\"Blues\")\n",
        "\n",
        "    ax.set_xticks([0, 1])\n",
        "    ax.set_yticks([0, 1])\n",
        "    ax.set_xticklabels([\"Pred 0\", \"Pred 1\"])\n",
        "    ax.set_yticklabels([\"Real 0\", \"Real 1\"])\n",
        "    ax.set_xlabel(\"Predicción\")\n",
        "    ax.set_ylabel(\"Real\")\n",
        "    ax.set_title(title)\n",
        "\n",
        "    threshold = cm.max() / 2 if cm.max() > 0 else 0\n",
        "    for i in range(2):\n",
        "        for j in range(2):\n",
        "            color = \"white\" if cm[i, j] > threshold else \"black\"\n",
        "            ax.text(j, i, labels[i, j], ha=\"center\", va=\"center\", color=color)\n",
        "\n",
        "    plt.colorbar(im, ax=ax)\n",
        "    plt.grid(False)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 1) CARGA DEL DATASET\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se carga el dataset consolidado de eventos de incendio, que contiene variables\n",
        "# climáticas, métricas de FRP y una etiqueta binaria real de riesgo. Este dataset\n",
        "# constituye la base para el entrenamiento y evaluación del modelo Ridge.\n",
        "\n",
        "DATA_PATH = \"/content/sample_data/Dataset_Incendios_Eventos_TARGET_RIESGO_FRP.csv\"\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "\n",
        "print(\"✅ Dataset cargado\")\n",
        "print(\"Shape:\", df.shape)\n",
        "display(df.head())\n",
        "print(\"Columnas disponibles:\", df.columns.tolist())\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 2) CONFIGURACIÓN DE COLUMNAS\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se definen explícitamente la variable objetivo de regresión, la etiqueta\n",
        "# real de clasificación y el conjunto de variables predictoras. Esta etapa\n",
        "# asegura coherencia entre el dataset y el diseño del modelo.\n",
        "\n",
        "TARGET_REG = \"frp_max\"\n",
        "TARGET_CLASS_REAL = \"target_riesgo\"\n",
        "FRP_INICIAL_COL = \"frp_inicial\"\n",
        "\n",
        "features = [\n",
        "    \"frp_inicial\",\n",
        "    \"temperature_2m_mean\", \"relativehumidity_2m_mean\",\n",
        "    \"windspeed_10m_mean\", \"precipitation_sum\",\n",
        "    \"temperature_2m_mean_lag1\", \"temperature_2m_mean_lag2\", \"temperature_2m_mean_lag3\",\n",
        "    \"relativehumidity_2m_mean_lag1\", \"relativehumidity_2m_mean_lag2\", \"relativehumidity_2m_mean_lag3\",\n",
        "    \"windspeed_10m_mean_lag1\", \"windspeed_10m_mean_lag2\", \"windspeed_10m_mean_lag3\",\n",
        "    \"precipitation_sum_lag1\", \"precipitation_sum_lag2\", \"precipitation_sum_lag3\"\n",
        "]\n",
        "\n",
        "# Validaciones\n",
        "for col in [TARGET_REG, TARGET_CLASS_REAL, FRP_INICIAL_COL]:\n",
        "    if col not in df.columns:\n",
        "        raise ValueError(f\"❌ Falta columna requerida: {col}\")\n",
        "\n",
        "missing = [c for c in features if c not in df.columns]\n",
        "if missing:\n",
        "    raise ValueError(f\"❌ Faltan columnas en features: {missing}\")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 3) X e y (regresión)\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se construyen las matrices de entrada (X) y salida (y) para el problema\n",
        "# de regresión. Se convierten los datos a formato numérico y se eliminan\n",
        "# observaciones inválidas para garantizar consistencia.\n",
        "\n",
        "X = df[features].apply(pd.to_numeric, errors=\"coerce\")\n",
        "y_reg = pd.to_numeric(df[TARGET_REG], errors=\"coerce\")\n",
        "\n",
        "mask = y_reg.notna() & df[FRP_INICIAL_COL].notna()\n",
        "X = X.loc[mask].reset_index(drop=True)\n",
        "y_reg = y_reg.loc[mask].reset_index(drop=True)\n",
        "\n",
        "y_class_real = df.loc[mask, TARGET_CLASS_REAL].astype(int).reset_index(drop=True)\n",
        "\n",
        "print(\"\\nDatos para modelar:\")\n",
        "print(\"X:\", X.shape, \"| y_reg:\", y_reg.shape)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 4) TRAIN / TEST SPLIT\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se divide el dataset en conjuntos de entrenamiento y prueba, permitiendo\n",
        "# evaluar el desempeño del modelo sobre datos no vistos.\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y_reg,\n",
        "    test_size=0.30,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 5) PIPELINE RIDGE + GRIDSEARCH\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se construye un pipeline que incluye imputación de valores faltantes,\n",
        "# escalado de variables y regresión Ridge. Se utiliza GridSearchCV para\n",
        "# seleccionar el parámetro de regularización óptimo (alpha).\n",
        "\n",
        "pipe_ridge = Pipeline(steps=[\n",
        "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
        "    (\"scaler\", StandardScaler()),\n",
        "    (\"ridge\", Ridge(random_state=42))\n",
        "])\n",
        "\n",
        "param_grid = {\"ridge__alpha\": [0.1, 1, 10, 100, 300]}\n",
        "\n",
        "gs = GridSearchCV(\n",
        "    pipe_ridge,\n",
        "    param_grid,\n",
        "    scoring=\"neg_mean_absolute_error\",\n",
        "    cv=5,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "gs.fit(X_train, y_train)\n",
        "model = gs.best_estimator_\n",
        "\n",
        "print(\"\\n✅ Ridge entrenado\")\n",
        "print(\"Mejor alpha:\", gs.best_params_[\"ridge__alpha\"])\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 6) MÉTRICAS REGRESIÓN\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se evalúa el desempeño del modelo de regresión utilizando métricas estándar\n",
        "# (MAE, RMSE y R²), que permiten cuantificar error y capacidad explicativa.\n",
        "\n",
        "y_pred_test = model.predict(X_test)\n",
        "\n",
        "print(\"\\nMétricas regresión (test):\")\n",
        "print(\"MAE :\", mean_absolute_error(y_test, y_pred_test))\n",
        "print(\"RMSE:\", np.sqrt(mean_squared_error(y_test, y_pred_test)))\n",
        "print(\"R²  :\", r2_score(y_test, y_pred_test))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 7) PREDICCIÓN FRP MAX PARA TODO EL DATASET\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# El modelo entrenado se utiliza para predecir el FRP máximo de todos los\n",
        "# eventos disponibles. Se aplica una restricción física para evitar valores\n",
        "# negativos.\n",
        "\n",
        "frp_max_pred = model.predict(X)\n",
        "frp_max_pred = np.maximum(frp_max_pred, 0)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 8) CLASIFICACIÓN POR FRP ≥ 100\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se construye una clasificación binaria operativa utilizando un umbral\n",
        "# fijo de FRP para identificar incendios intensos.\n",
        "\n",
        "THR_FRP = 100.0\n",
        "pred_intenso = (frp_max_pred >= THR_FRP).astype(int)\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 9) DATASET DE SALIDA CON NUEVAS COLUMNAS\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se genera un dataset de salida que incorpora las predicciones del modelo\n",
        "# y la clasificación derivada, manteniendo trazabilidad con los eventos\n",
        "# originales.\n",
        "\n",
        "df_out = df.loc[mask].copy().reset_index(drop=True)\n",
        "\n",
        "df_out[\"frp_max_pred_ridge\"] = frp_max_pred\n",
        "df_out[\"pred_intenso_frp100\"] = pred_intenso\n",
        "df_out[\"umbral_frp\"] = THR_FRP\n",
        "\n",
        "print(\"\\n✅ Dataset con nuevas columnas:\")\n",
        "display(df_out[[\n",
        "    \"event_id_final\",\n",
        "    \"frp_inicial\",\n",
        "    \"frp_max\",\n",
        "    \"frp_max_pred_ridge\",\n",
        "    \"pred_intenso_frp100\",\n",
        "    TARGET_CLASS_REAL\n",
        "]].head())\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 10) MÉTRICAS DE CLASIFICACIÓN\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se evalúa el desempeño del modelo desde una perspectiva de clasificación,\n",
        "# comparando las predicciones binarias con la etiqueta real de riesgo.\n",
        "\n",
        "prec = precision_score(y_class_real, pred_intenso, zero_division=0)\n",
        "rec  = recall_score(y_class_real, pred_intenso, zero_division=0)\n",
        "f1   = f1_score(y_class_real, pred_intenso, zero_division=0)\n",
        "\n",
        "print(\"\\n================= MÉTRICAS CLASIFICACIÓN ================\")\n",
        "print(f\"Umbral FRP_max_pred ≥ {THR_FRP}\")\n",
        "print(f\"Precision: {prec:.3f}\")\n",
        "print(f\"Recall   : {rec:.3f}\")\n",
        "print(f\"F1       : {f1:.3f}\")\n",
        "\n",
        "print(\"\\nReporte de clasificación:\")\n",
        "print(classification_report(y_class_real, pred_intenso, digits=3, zero_division=0))\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 11) MATRIZ DE CONFUSIÓN (PALETA BLUES)\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se visualiza la matriz de confusión para analizar los aciertos y errores\n",
        "# del modelo Ridge en la clasificación de incendios intensos.\n",
        "\n",
        "plot_confusion_with_labels_blues(\n",
        "    y_class_real,\n",
        "    pred_intenso,\n",
        "    title=\"Matriz de confusión — Ridge (FRP_max_pred ≥ 100)\"\n",
        ")\n",
        "\n",
        "\n",
        "# -----------------------------\n",
        "# 12) (OPCIONAL) GUARDAR DATASET\n",
        "# -----------------------------\n",
        "# Descripción:\n",
        "# Se exporta el dataset final con las predicciones del modelo Ridge para\n",
        "# su uso en análisis posteriores o comparación con otros modelos.\n",
        "\n",
        "df_out.to_csv(\n",
        "    \"Dataset_Ridge_FRP100_clasificado.csv\",\n",
        "    index=False,\n",
        "    sep=\";\",\n",
        "    decimal=\".\"\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Interpretación de las métricas (FRP ≥ 100)**\n",
        "\n",
        "\n",
        "Al evaluar el desempeño del modelo Ridge Regression bajo el criterio operativo FRP ≥ 100, las métricas relevantes para la clase positiva (evento intenso) son las siguientes:\n",
        "\n",
        "Precision: 0.371\n",
        "\n",
        "Recall: 0.038\n",
        "\n",
        "F1-score: 0.070\n",
        "\n",
        "Estos valores indican de forma inequívoca que el modelo prácticamente no detecta los eventos de incendio intensos.\n",
        "\n",
        "**Análisis técnico detallado**\n",
        "\n",
        "Recall = 0.038 (crítico)\n",
        "\n",
        "El recall de 0.038 implica que el modelo identifica solo alrededor del 4 % de los eventos intensos reales, perdiendo aproximadamente el 96 % de los incendios con FRP ≥ 100.\n",
        "\n",
        "En el contexto de un sistema de alerta temprana o priorización operativa, este nivel de sensibilidad es inaceptable, ya que la mayoría de los eventos críticos no serían detectados.\n",
        "\n",
        "Precision = 0.371\n",
        "\n",
        "Una precisión de 0.371 indica que, cuando el modelo emite una alerta, acierta en aproximadamente el 37 % de los casos. Este valor no es extremadamente bajo debido a que el modelo emite muy pocas alertas.\n",
        "\n",
        "Este comportamiento corresponde al patrón típico de un clasificador conservador:\n",
        "\n",
        "“El modelo casi nunca alerta, pero cuando lo hace, ocasionalmente acierta”.\n",
        "\n",
        "Accuracy = 0.874 (métrica engañosa)\n",
        "\n",
        "Aunque la exactitud global alcanza un valor elevado (≈ 0.874), esta métrica no es informativa en este problema.\n",
        "\n",
        "La razón es el fuerte desbalance de clases:\n",
        "\n",
        "Clase 0 (no intenso): ~2420 eventos\n",
        "\n",
        "Clase 1 (intenso): ~339 eventos\n",
        "\n",
        "El modelo obtiene un accuracy alto simplemente porque predice mayoritariamente la clase 0.\n",
        "Un accuracy alto no implica un buen modelo, y este punto es crucial de explicitar para evitar interpretaciones erróneas, especialmente en evaluaciones académicas.\n",
        "\n",
        "Por qué FRP ≥ 100 es especialmente difícil para Ridge\n",
        "\n",
        "El bajo desempeño del modelo Ridge no es casual, sino que responde a limitaciones estructurales del enfoque lineal en este problema.\n",
        "\n",
        "1) El umbral se encuentra dentro del rango de error del modelo\n",
        "\n",
        "Los resultados de regresión muestran:\n",
        "\n",
        "MAE ≈ 42\n",
        "\n",
        "RMSE ≈ 76\n",
        "\n",
        "El umbral operativo de 100 MW se sitúa aproximadamente entre 1 y 2 veces el error típico del modelo.\n",
        "\n",
        "En este contexto, el modelo carece de resolución suficiente para discriminar de forma confiable si un evento superará o no dicho umbral.\n",
        "\n",
        "2) La regularización de Ridge atenúa los valores extremos\n",
        "\n",
        "El valor óptimo de regularización encontrado (α = 300) induce al modelo a penalizar fuertemente coeficientes grandes, lo que se traduce en:\n",
        "\n",
        "Predicciones más suavizadas,\n",
        "\n",
        "Subestimación sistemática de valores altos de FRP.\n",
        "\n",
        "Como consecuencia, los eventos con FRP ≥ 100 quedan mal representados, afectando directamente la capacidad de detección de incendios intensos.\n",
        "\n",
        "3) El fenómeno subyacente no es lineal\n",
        "\n",
        "El bajo poder explicativo del modelo (R² ≈ 0.08) evidencia que la relación entre las variables predictoras y el FRP máximo:\n",
        "\n",
        "presenta interacciones complejas,\n",
        "\n",
        "incluye comportamientos no lineales,\n",
        "\n",
        "y responde a dinámicas explosivas y umbrales abruptos.\n",
        "\n",
        "Un modelo lineal regularizado como Ridge no puede capturar adecuadamente estas características, lo que limita estructuralmente su desempeño.\n",
        "\n",
        "**Conclusión**\n",
        "\n",
        "El pobre desempeño del modelo Ridge bajo el criterio FRP ≥ 100 no debe interpretarse como un fallo de implementación, sino como una demostración empírica de sus limitaciones frente a un fenómeno complejo, no lineal y desbalanceado. Este resultado refuerza la necesidad de emplear modelos no lineales, como Random Forest o redes neuronales, para abordar eficazmente este tipo de problemas."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
